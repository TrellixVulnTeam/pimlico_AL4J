# Specify some things in variables at the top of the file, so they're easy to find
[vars]
# The main pipeline input dir is given here
# We use a tiny fragment of the publicly available sample of Gigaword
text_path=%(pimlico_root)s/examples/data/gigaword_sample.gz


# Options for the whole pipeline
[pipeline]
name=opennlp_parse_test
# Specify the version of Pimlico this config is designed to work with
# It will run with any release that's the same major version and the same or a later minor version
# Here we use "latest" so we're always testing against the latest version, but you should specify the version you
#  wrote the pipeline for
release=latest
# Here you can add path(s) to Python source directories the pipeline needs
# Typically, you'll just add a single path, specified relative to the config file's location
python_path=


# An input module to read in the text from Gigaword XML
[input-text]
type=pimlico.datatypes.XmlDocumentIterator
# Here we use the path we specified above
path=%(text_path)s


# Run the extracted input data through a tar filter, which groups it into manageable batches for further processing
# Since this is a filter, it doesn't need to be executed: the output from input-text gets passed through it when needed
[tar-grouper]
type=pimlico.modules.corpora.tar_filter
input=input-text


# A module that does something! Tokenization
[tokenize]
type=pimlico.modules.opennlp.tokenize
input=tar-grouper

[pos-tag]
type=pimlico.modules.opennlp.pos
input=tokenize
