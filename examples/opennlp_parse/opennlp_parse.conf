# Specify some things in variables at the top of the file, so they're easy to find
[vars]
# The main pipeline input dir is given here
text_path=/usr/groups/corpora-cds/gigaword_eng/data/afp_eng/


# Options for the whole pipeline
[pipeline]
name=opennlp_parse
# Specify the version of Pimlico this config is designed to work with
# It will run with any release that's the same major version and the same or a later minor version
release=0.1


# An input module to read in the text from Gigaword XML
[input-text]
type=pimlico.datatypes.XmlDocumentIterator
# Here we use the path we specified above
path=%(text_path)s


# To make it easier to try out our pipeline, just use the first part of the corpus
[small-subset]
type=pimlico.modules.corpora.subset
input=input-text
size=1000


# Run the extracted input data through a tar filter, which groups it into manageable batches for further processing
# Since this is a filter, it doesn't need to be executed: the output from input-text gets passed through it when needed
[tar-grouper]
type=pimlico.modules.corpora.tar_filter
input=small-subset


# A module that does something! Tokenization
[tokenize]
type=pimlico.modules.opennlp.tokenize
input_text=tar-grouper

#[pos-tag]
