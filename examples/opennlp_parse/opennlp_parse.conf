# Specify some things in variables at the top of the file, so they're easy to find
[vars]
# The main pipeline input dir is given here
text_path=/usr/groups/corpora-cds/gigaword_eng/data/afp_eng/


# Options for the whole pipeline
[pipeline]
name=opennlp_parse
# Specify the version of Pimlico this config is designed to work with
# It will run with any release that's the same major version and the same or a later minor version
release=0.1
# Here you can add path(s) to Python source directories the pipeline needs
# Typically, you'll just add a single path, specified relative to the config file's location
python_path=


# An input module to read in the text from Gigaword XML
[input-text]
type=pimlico.datatypes.XmlDocumentIterator
# Here we use the path we specified above
path=%(text_path)s
# For now, just extract a small subset
truncate=1000


# Run the extracted input data through a tar filter, which groups it into manageable batches for further processing
# Since this is a filter, it doesn't need to be executed: the output from input-text gets passed through it when needed
[tar-grouper]
type=pimlico.modules.corpora.tar_filter
input=input-text


# A module that does something! Tokenization
[tokenize]
type=pimlico.modules.opennlp.tokenize
input=tar-grouper

[pos-tag]
type=pimlico.modules.opennlp.pos
input=tokenize
